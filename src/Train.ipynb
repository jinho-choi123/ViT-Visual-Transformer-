{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5710d848-ca35-4c38-b76d-3d984b7a2493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Vit using Food101 dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f86868b-1470-42be-ae97-9cd3d7aa4ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "%run config.ipynb\n",
    "%run data-install.ipynb\n",
    "%run ViT.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97823546-22b7-45d8-845c-1a22a4c7a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam \n",
    "from datetime import datetime \n",
    "import torch \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20415737-0e48-457c-9988-b6d42d9727ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ViT(\n",
    "    image_size=IMG_SIZE,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    in_channels=IN_CHANNELS,\n",
    "    n_head=N_HEAD, \n",
    "    d_model=D_MODEL, \n",
    "    ffn_hidden=FFN_HIDDEN, \n",
    "    mlp_hidden=MLP_HIDDEN, \n",
    "    n_layers=N_LAYERS, \n",
    "    class_num=CLASS_NUM, \n",
    "    device=device, \n",
    "    drop_prob=DROP_PROB,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "\n",
    "def count_parameters(model): \n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad) \n",
    "\n",
    "logger.info(f'model parameter #: {count_parameters(model)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99b490b3-e88f-4599-b33b-7c1e530a517f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup optimizer \n",
    "optimizer = Adam(params = model.parameters(), lr=INIT_LR, decay=WEIGHT_DECAY)\n",
    "\n",
    "# Setup loss function for training \n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eac9adba-1e11-4070-a4b8-6192b8bfdcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_per_epoch = []\n",
    "test_loss_per_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab542c29-a836-47e1-812d-ea27008b282a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch_num): \n",
    "    # Prepare recording CUDA memory snapshot\n",
    "    # torch.cuda.memory._record_memory_history(\n",
    "    #     max_entries=100000\n",
    "    # )\n",
    "    model.train()\n",
    "    train_epoch_loss = 0 \n",
    "\n",
    "    for step, (img, food) in tqdm(enumerate(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        img = img.to(device)\n",
    "        food = food.to(device)\n",
    "        out, _ = model(img)\n",
    "\n",
    "        loss = loss_func(out, food)\n",
    "        \n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        train_epoch_loss += loss.item()\n",
    "\n",
    "        if step % 200 == 0: \n",
    "            logger.info(f'EPOCH #{epoch_num} STEP #{step} | loss: {loss.item()}, avg_loss: {train_epoch_loss / (step + 1)}')\n",
    "\n",
    "        # if step == 100:\n",
    "        #     try:\n",
    "        #         memory_dump_path = log_dir / f'memory_dump_{timestamp}.log'\n",
    "        #         torch.cuda.memory._dump_snapshot(memory_dump_path)\n",
    "        #         # stop recording memory history\n",
    "        #         torch.cuda.memory._record_memory_history(enabled=None)\n",
    "        #     except Exception as e:\n",
    "        #         logger.error(f'Failed to capture memory snapshot {e}')\n",
    "            \n",
    "\n",
    "    train_step_loss = train_epoch_loss / (step + 1) \n",
    "    return train_epoch_loss, train_step_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f6cd28-46d1-4607-b2c0-8f6f8fd09ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    model.eval()\n",
    "    test_epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (img, food) in tqdm(enumerate(test_dataloader)):\n",
    "            img = img.to(device)\n",
    "            food = food.to(device)\n",
    "            out, _ = model(img)\n",
    "\n",
    "            loss = loss_func(out, food)\n",
    "\n",
    "            test_epoch_loss += loss.item()\n",
    "\n",
    "    test_step_loss = test_epoch_loss / (step + 1)\n",
    "\n",
    "    return test_epoch_loss, test_step_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910b3ff-4e9e-459c-b55d-b4011614fb8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Actual training is done here\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    train_epoch_loss, train_step_loss = train_epoch(epoch)\n",
    "    test_epoch_loss, test_step_loss = evaluate()\n",
    "\n",
    "    train_loss_per_epoch.append(train_step_loss)\n",
    "    test_loss_per_epoch.append(test_step_loss)\n",
    "\n",
    "    logger.info(f'Epoch #{epoch} End | Train Loss: {train_step_loss} | Test Loss: {test_step_loss}')\n",
    "\n",
    "    model_path = model_dir / f'model_{timestamp}_{epoch}'\n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "logger.info(f'Training Completely Ended!!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e551b7f-8f6c-49dc-a3f2-8b6e1f25d78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
